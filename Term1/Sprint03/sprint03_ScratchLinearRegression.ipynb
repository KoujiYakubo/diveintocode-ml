{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ 線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchLinearRegressionクラスにコードを書き加えていってください。\n",
    "\n",
    "### ScratchLinearRegressionクラス 雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。  \n",
    "$\n",
    "hθ(x)=θ0x0+θ1x1+...+θjxj+...+θnxn.(x0=1)\n",
    "$  \n",
    "\n",
    "x : 特徴量ベクトル  \n",
    "θ : パラメータベクトル  \n",
    "n : 特徴量の数  \n",
    "xj : j番目の特徴量  \n",
    "θj : j番目のパラメータ（重み）  \n",
    "\n",
    "特徴量の数nは任意の値に対応できる実装にしてください。\n",
    "\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。  \n",
    "$hθ(x)=θT⋅x.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仮定関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        # h = np.dot(theta, X.T)\n",
    "        h = np.dot(self.coef_, X.T)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】最急降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}[(h_\\theta(x^{(i)}) - y^{(i)} )x_{j}^{(i)}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        最急降下法による学習\n",
    "        \"\"\"\n",
    "        # alpha = self.lr\n",
    "        # theta = np.array([1,2,3])\n",
    "        m = len(X)\n",
    "        # print(theta)\n",
    "        self.coef_ = self.coef_ - self.lr * (1/m)*np.dot( error, X)\n",
    "        # theta = ( theta,X).sum()\n",
    "\n",
    "        return self.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "\n",
    "仮定関数 $h_\\theta(x)$ の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        y_pred = linear_hypothesis(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】平均二乗誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\theta)=  \\frac{1 }{ m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m$ : 入力されるデータの数\n",
    "\n",
    "\n",
    "$h_\\theta()$ : 仮定関数\n",
    "\n",
    "\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解値\n",
    "\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    # print(y_pred)\n",
    "    m = len(y) \n",
    "    mse = 1/m * ((y_pred - y)**2).sum()\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】目的関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "\n",
    "目的関数（損失関数） $J(\\theta)$ は次の式です。\n",
    "\n",
    "$$\n",
    "J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$\n",
    "\n",
    "$m$ : 入力されるデータの数\n",
    "\n",
    "\n",
    "$h_\\theta()$ : 仮定関数\n",
    "\n",
    "\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解値\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ loss(self, verbose):\n",
    "    if self.loss is == True:\n",
    "        J = 1/2m * sum((ypred - y)**2)\n",
    "    else self.val_loss is == True:\n",
    "        J = 1/2m * sum((ypred - y)**2)\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題1〜5を反映したコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,) \n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        # self.coef_ = 10\n",
    "        self.coef_ = None\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # print(X.shape)\n",
    "        # if X_val is not None:\n",
    "        #    print(X_val.shape)\n",
    "        \n",
    "        # バイアスの有無\n",
    "        if self.no_bias is not True:\n",
    "            X = np.insert(X, 0, 2, axis=1)\n",
    "        if X_val is not None:\n",
    "            X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "        # print(X)\n",
    "        \n",
    "        self.coef_ = np.random.rand(X.shape[1])\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "\n",
    "            y_pred = self._linear_hypothesis(X)\n",
    "            error = y_pred - y\n",
    "            self.coef_ = self._gradient_descent(X, error)\n",
    "            m = len(y_pred)\n",
    "            J = 1/2* ((error)**2).sum() / m\n",
    "            self.loss[i] = J\n",
    "            # print(self.loss)\n",
    "            \n",
    "            if self.verbose is True:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                print(\"{}回目:{}\".format(i, J))\n",
    "            \n",
    "            # X_valがある場合\n",
    "            if X_val is not None:\n",
    "                # print(X.shape, X_val.T.shape)\n",
    "                y_pred_val = self._linear_hypothesis(X_val)\n",
    "                error_val = y_pred_val - y_val\n",
    "                val_m = len(y_pred_val)\n",
    "                val_J = 1/2* ((error_val)**2).sum() / val_m\n",
    "                self.val_loss[i] = val_J\n",
    "                # print(self.val_loss)\n",
    "\n",
    "                if self.verbose is True:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                    # print(\"{}回目:{} - {}\".format(i, val_J,self.coef_))\n",
    "                    print(\"{}回目:{}\".format(i, val_J))\n",
    "                \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        y_pred = linear_hypothesis(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        # h = np.dot(theta, X.T)\n",
    "        h = np.dot(self.coef_, X.T)\n",
    "        return h\n",
    "\n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        最急降下法による学習\n",
    "        \"\"\"\n",
    "        # alpha = self.lr\n",
    "        # theta = np.array([1,2,3])\n",
    "        m = len(X)\n",
    "        # print(theta)\n",
    "        self.coef_ = self.coef_ - self.lr * (1/m)*np.dot( error, X)\n",
    "        # theta = ( theta,X).sum()\n",
    "\n",
    "        return self.coef_\n",
    "\n",
    "\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    # print(y_pred)\n",
    "    m = len(y) # 不要かもしれない\n",
    "    mse = 1/m * ((y_pred - y)**2).sum()\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_original = pd.read_csv(\"dataset/train.csv\")\n",
    "df = df_original[[\"GrLivArea\", \"YearBuilt\", \"SalePrice\"]]\n",
    "\n",
    "# 説明変数と目的変数に分割し、ndarrayに変換\n",
    "X = df[[\"GrLivArea\", \"YearBuilt\"]].values\n",
    "y = df[[\"SalePrice\"]].values\n",
    "\n",
    "#データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化処理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295.5162641646213"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#スクラッチによる推定\n",
    "regress = ScratchLinearRegression(num_iter=100, lr=0.01, no_bias=False, verbose=False)\n",
    "regress.fit(X_train, y_train.ravel(), X_test,  y_test.ravel())\n",
    "#regress.fit(X_test,  y_test.ravel(), X_train, y_train.ravel())\n",
    "MSE(y_pred_liner, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.7933846903892"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scilit-learnによる推定\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train.ravel())\n",
    "y_pred_sl = model.predict(X_train)\n",
    "MSE(y_pred_sl, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(loss, val_loss):\n",
    "\n",
    "    fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "    axL.plot(loss, c=\"b\")\n",
    "    axL.set_xlabel(\"Iteration\")\n",
    "    axL.set_ylabel(\"loss\")\n",
    "    axL.grid()\n",
    "\n",
    "    axR.plot(val_loss, c=\"r\")\n",
    "    axR.set_xlabel(\"Iteration\")\n",
    "    axR.set_ylabel(\"loss\")\n",
    "    axR.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plot_learning_curve(regress.loss, regress.val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
