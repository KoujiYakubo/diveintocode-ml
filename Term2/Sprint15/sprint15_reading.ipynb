{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 論文読解入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。\n",
    "\n",
    "\n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1506.01497.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SPPnet\n",
    "- Fast R-CNN\n",
    "\n",
    "P1の Abstract より引用\n",
    "> Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最新の物体検出と畳み込み層を共有するRPNsを導入し、オブジェクト提案のコストを削減することで高速化を実現\n",
    "\n",
    "P1のINTRODUCTIONより引用\n",
    "\n",
    "> In this paper, we show that an algorithmic change— computing proposals with a deep convolutional neu- ral network—leads to an elegant and effective solution where proposal computation is nearly cost-free given the detection network’s computation. To this end, we introduce novel Region Proposal Networks (RPNs) that share convolutional layers with state-of-the-art object detection networks [1], [2]. By sharing convolutions at test-time, the marginal cost for computing proposals is small (e.g., 10ms per image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。\n",
    "- One-Stageは検出提案のプロセスを分離しないフレームワーク\n",
    "- Two-Stageはオブジェクト提案を生成するための前処理ステップを含む2段階の検出フレームワーク。\n",
    "\n",
    "https://arxiv.org/pdf/1809.02165.pdf のP1「5 Detection Frameworks」より引用\n",
    "> a. Two stage detection frameworks, which include a preprocess- ing step for generating object proposals;\n",
    "b. One stage detection frameworks,orregion proposal free frame-works, having a single proposed method which does not separate the process of the detection proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RPNは各位置でオブジェクトの境界とオブジェクトのスコアを同時に予測する全畳み込みネットワークである。\n",
    "\n",
    "P1.Abstract より引用\n",
    "> An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最大プーリングを使用して、有効な関心領域内の機能をH×W（たとえば、7×7）の固定空間範囲を持つ小さな特徴マップに変換すること。\n",
    "\n",
    "https://arxiv.org/pdf/1504.08083.pdf の P2 「2.1. The RoI pooling layer」より引用\n",
    "> The RoI pooling layer uses max pooling to convert thefeatures inside any valid region of interest into a small fea-ture map with a fixed spatial extent ofH×W(e.g.,7×7),where H and W are layer hyper-parameters that are inde-pendent  of  any  particular  RoI.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Anchorのサイズはどうするのが適切か。\n",
    "- 3つのスケールと3つのアスペクト比を使用し、各スライド位置でk = 9個のアンカーを生成するのがデフォルトです。\n",
    "\n",
    "P4「3.1.1 Anchors」より引用\n",
    "> by default we use 3 scales and 3 aspect ratios, yielding k = 9 anchors at each sliding position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MS COCO というデータセットを使用し、Faster R-CNN は Fast R-CNNよりもmAP@0.5で2.8%、mAP@[.5, .95]で2.2%高い数値を得ることができた\n",
    "\n",
    "P11「4.2 Experiments on MS COCO」より引用\n",
    "> Next we evaluate our Faster R-CNN system. Using the COCO training set to train, Faster R-CNN has 42.1% mAP@0.5 and 21.5% mAP@[.5, .95] on the COCO test-dev set. This is 2.8% higher for mAP@0.5 and 2.2% higher for mAP@[.5, .95] than the Fast R- CNN counterpart under the same protocol (Table 11). This indicates that RPN performs excellent for im-proving the localization accuracy at higher IoU thresh- olds. Using the COCO trainval set to train, Faster R- CNN has 42.7% mAP@0.5 and 21.9% mAP@[.5, .95] on the COCO test-dev set. Figure 6 shows some results on the MS COCO test-dev set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
