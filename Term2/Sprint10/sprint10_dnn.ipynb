{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ ディープニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平滑化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1 ,784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# print(X_train.max()) # 1.0\n",
    "# print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot表現への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "# print(y_train.shape) #(60000, 10)\n",
    "# print(y_train_one_hot.shape) #(60000, 10)\n",
    "# print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ6万枚の内2割を検証データとして分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "# print(X_train.shape) # (48000, 784)\n",
    "# print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチ処理《コード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "# print(len(get_mini_batch)) # 2400\n",
    "# print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】全結合層のクラス化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.WH = 0\n",
    "        self.BH = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.X = X\n",
    "        A = self.X@self.W + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = dA\n",
    "        self.dW = np.mean(self.X, axis=0).T.reshape(-1, 1) @ self.dA\n",
    "        self.dB = self.dA\n",
    "    \n",
    "        dZ = self.dA @ self.W.T \n",
    "        self = self.optimizer.update(self) \n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W = layer.W - self.lr*layer.dW\n",
    "        layer.B = layer.B - self.lr*layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * (1 - np.tanh(np.mean(self.A, axis=0))**2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def forward(self, A):\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        dA = np.mean(Z - Y, axis=0).reshape(1, -1) #shape(1, 10)\n",
    "        self.loss = -1 * np.mean(np.sum(Y * np.log(Z), axis=1))\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】ReLUクラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "$\n",
    "f(x) = ReLU(x) = \\begin{cases}\n",
    "x  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "x\n",
    " : ある特徴量。スカラー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        Z = np.where(self.X>0, self.X, 0)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.X>0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavierの初期値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heの初期値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2/n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self):\n",
    "        self.lr = 0.01\n",
    "        self.WH = np.zeros(1)\n",
    "        self.BH = np.zeros(1)\n",
    "        pass\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.WH = layer.WH + layer.dW * layer.dW\n",
    "        layer.BH = layer.BH + layer.dB * layer.dB\n",
    "        layer.W = layer.W - self.lr*np.sqrt(layer.WH) * layer.dW\n",
    "        layer.B = layer.B - self.lr*np.sqrt(layer.BH) * layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch=2, lr=0.01, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.mini_y_train = None\n",
    "        self.train_loss_list = []\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 200\n",
    "        self.sigma = 0.01 \n",
    "        batch_size = 20\n",
    "        self.n_output = 10\n",
    "        \n",
    "        optimizer = SGD(self.lr)\n",
    "        \n",
    "        get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "        if self.verbose:\n",
    "            print(\"train data learning process\\n\")\n",
    "            \n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, XavierInitializer(), optimizer)\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, XavierInitializer(), optimizer)\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, XavierInitializer(), optimizer)\n",
    "        \n",
    "        for _ in range(self.epoch):\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.mini_y_train = mini_y_train\n",
    "                \n",
    "                self.activation1 = Tanh()\n",
    "                A1 = self.FC1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                \n",
    "                self.activation2 = Tanh()\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                \n",
    "                self.activation3 = Softmax()\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                dA3 = self.activation3.backward(Z3, self.mini_y_train) \n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) \n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(\"W1\\n{}\\n\".format(self.W1))\n",
    "                    print(\"W2\\n{}\\n\".format(self.W2))\n",
    "                    print(\"W3\\n{}\\n\".format(self.W3))\n",
    "                    print(\"B1\\n{}\\n\".format(self.B1))\n",
    "                    print(\"B2\\n{}\\n\".format(self.B2))\n",
    "                    print(\"B3\\n{}\\n\".format(self.B3))\n",
    "                    pass\n",
    "            self.train_loss_list.append(self.activation3.loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        \n",
    "        y_pred = Z3\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier1():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers=3, n_nodes=200, epoch=2, lr=0.01, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.mini_y_train = None\n",
    "        self.train_loss_list = []\n",
    "        self.n_layers = n_layers\n",
    "        self.n_nodes = n_nodes\n",
    "        self.FC_list = []\n",
    "        self.activation_list = []\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        self.sigma = 0.01\n",
    "        batch_size = 20\n",
    "        self.n_output = 10\n",
    "        \n",
    "        optimizer = SGD(self.lr)\n",
    "        \n",
    "        get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "        if self.verbose:\n",
    "            print(\"learning process.....\\n\")\n",
    "            \n",
    "        for i in range(self.n_layers):\n",
    "            if i==0:\n",
    "                self.FC_list.append(FC(self.n_features, self.n_nodes, XavierInitializer(), optimizer))\n",
    "                self.activation_list.append(Tanh())\n",
    "            \n",
    "            elif i==self.n_layers-1:\n",
    "                self.FC_list.append(FC(self.n_nodes, self.n_output, XavierInitializer(), optimizer))\n",
    "                self.activation_list.append(Softmax())\n",
    "            else:\n",
    "                self.FC_list.append(FC(self.n_nodes, self.n_nodes, XavierInitializer(), optimizer))\n",
    "                self.activation_list.append(Tanh())\n",
    "        \n",
    "        for _ in range(self.epoch):\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.mini_y_train = mini_y_train\n",
    "                \n",
    "                for i in range(self.n_layers):\n",
    "                    if i==0:\n",
    "                        A = self.FC_list[i].forward(mini_X_train)\n",
    "                        Z = self.activation_list[i].forward(A)\n",
    "                    else:\n",
    "                        A = self.FC_list[i].forward(Z)\n",
    "                        Z = self.activation_list[i].forward(A)\n",
    "                        \n",
    "                for i in range(self.n_layers):\n",
    "                    if i==0:\n",
    "                        dA = self.activation_list[-(i+1)].backward(Z, self.mini_y_train)\n",
    "                        dZ = self.FC_list[-(i+1)].backward(dA)\n",
    "                    else:\n",
    "                        dA = self.activation_list[-(i+1)].backward(dZ)\n",
    "                        dZ = self.FC_list[-(i+1)].backward(dA)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(\"W1\\n{}\\n\".format(self.W1))\n",
    "                    print(\"W2\\n{}\\n\".format(self.W2))\n",
    "                    print(\"W3\\n{}\\n\".format(self.W3))\n",
    "                    print(\"B1\\n{}\\n\".format(self.B1))\n",
    "                    print(\"B2\\n{}\\n\".format(self.B2))\n",
    "                    print(\"B3\\n{}\\n\".format(self.B3))\n",
    "                    \n",
    "            self.train_loss_list.append(self.activation_list[-1].loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for i in range(self.n_layers):\n",
    "            if i==0:\n",
    "                A = self.FC_list[i].forward(X)\n",
    "                Z = self.activation_list[i].forward(A)\n",
    "            else:\n",
    "                A = self.FC_list[i].forward(Z)\n",
    "                Z = self.activation_list[i].forward(A)\n",
    "                \n",
    "        y_pred = Z\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.894\n"
     ]
    }
   ],
   "source": [
    "nn1 = ScratchDeepNeuralNetrowkClassifier1(n_layers=5, n_nodes=200, epoch=30, lr=0.01, verbose=False)\n",
    "nn1.fit(X_train, y_train, X_val, y_val)\n",
    "y_pred = nn1.predict(X_val)\n",
    "print(\"Accuracy:{}\".format(metrics.accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(nn1.train_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
