{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self , W , B ,  stride=1 , pad=0 ):\n",
    "        self.W = W\n",
    "        self.B = B\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        self.hw = 0\n",
    "        self.hb = 0\n",
    "\n",
    "    def _out_h(self , H , FH , pad_h=0 , stride_h=1):\n",
    "        self.out_h = int(H + 2*pad_h - FH // stride_h+1)\n",
    "        return self.out_h        \n",
    "\n",
    "    def _out_w(self , W , FW , pad_w=0 , stride_w=1):\n",
    "        self.out_w = int(W + 2*pad_w - FW // stride_w+1)\n",
    "        return self.out_w\n",
    "    \n",
    "    def _im2col(self , X , FH , FW):\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = self._out_h(H , W)\n",
    "        out_w = self._out_w(W , FW)\n",
    "\n",
    "        img = np.pad(X , [(0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)] , \"constant\")\n",
    "        col = np.zeros((N , C , FH , FW , out_h , out_w))\n",
    "\n",
    "        for y in range(FH):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + self.stride*out_w\n",
    "                col[: , : , y , x , : , :] = img[: , : , y:y_max:self.stride, x:x_max:self.stride]\n",
    "\n",
    "        col = col.transpose(0 , 4 , 5 , 1 , 2 , 3).reshape(N*out_h*out_w, -1)\n",
    "        return col\n",
    "\n",
    "    def _col2im(self , dcol , X , FH , FW):\n",
    "        N , C , H , W = self.X.shape\n",
    "        out_h = self._out_h(H , FH)\n",
    "        out_w = self._out_w(W , FW)\n",
    "        col = dcol.reshape(N , out_h , out_W , C , FH , FW).transpose(0,3,4,5,1,2)\n",
    "\n",
    "        img = np.zeros(N , C , H , 2*self.pad + self.stride-1 , W + 2*self.pad + self.stride-1)\n",
    "        for y in range(FH):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + self.stride*out_w\n",
    "                img[: , : , y:y_max:self.stride , x:x_max:self.stride] += col[: , : , y , x , : , :]\n",
    "\n",
    "        return img[: , : , pad:H+pad , pad:W+pad]\n",
    "\n",
    "    def forward(self , X):\n",
    "        FN , C , FH , FW = self.W.shape\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = self._out_h(H , FH)\n",
    "        out_w = self._out_w(W , FW)\n",
    "        \n",
    "        col = self._im2col(X , FH , FW)\n",
    "        col_W = self.W.reshape(FN , -1).T\n",
    "        \n",
    "        A = np.dot(col , col_W) + self.B\n",
    "        A = A.reshape(N , out_h , out_w , -1).transpose(0 , 3 , 1 , 2)\n",
    "        \n",
    "        self.X = X\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self , dA):\n",
    "        FN , C , FH , FW = self.W.shape\n",
    "        dA = dA.transpose(0 , 2 , 3 , 1).reshape(-1 , FN)\n",
    "        \n",
    "        self.dB = np.sum(dA , axis = 0)\n",
    "        self.dW = np.dot(self.col.T , dA)\n",
    "        self.dW = self.dW.transpose(1 , 0).reshape(FN , C , FH ,FW)\n",
    "        \n",
    "        dcol = np.dot(dA , self.col_W.T)\n",
    "        dX = _col2im(dcol , X  , FH , FW)\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_h(H , FH , stride_h=1 , pad_h=0):\n",
    "    int(H + 2*pad_h - FH // stride_h+1)\n",
    "    return out_h\n",
    "\n",
    "def out_w(W , FW , stride_w=1 , pad_w=0):\n",
    "    int(W + 2*pad_w - FW // stride_w+1)\n",
    "    return out_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "\n",
    "$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self , pool_h , pool_w , stride=2 , pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.X = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def _im2col(self , X , FH , FW):\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = (H + 2*self.pad - FH)//self.stride + 1\n",
    "        out_w = (W + 2*self.pad - FW)//self.stride + 1\n",
    "\n",
    "        img = np.pad(X , [(0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)] , \"constant\")\n",
    "        col = np.zeros((N , C , FH , FW , out_h , out_w))\n",
    "\n",
    "        for y in range(FH):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + self.stride*out_w\n",
    "                col[: , : , y , x , : , :] = img[: , : , y:y_max:self.stride, x:x_max:self.stride]\n",
    "\n",
    "        col = col.transpose(0 , 4 , 5 , 1 , 2 , 3).reshape(N*out_h*out_w, -1)\n",
    "        return col\n",
    "    \n",
    "    def _col2im(self , dcol , X , FH , FW):\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = (H + 2*self.pad - FH)//self.stride + 1\n",
    "        out_w = (W + 2*self.pad - FW)//self.stride + 1\n",
    "        col = dcol.reshape(N , out_h , out_w , C , FH , FW).transpose(0,3,4,5,1,2)\n",
    "\n",
    "        img = np.zeros((N , C , H + 2*self.pad + self.stride-1 , W + 2*self.pad + self.stride-1))\n",
    "        for y in range(FH):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + self.stride*out_w\n",
    "                img[: , : , y:y_max:self.stride , x:x_max:self.stride] += col[: , : , y , x , : , :]\n",
    "\n",
    "        return img[: , : , self.pad:H+self.pad , self.pad:W+self.pad]\n",
    "      \n",
    "    def forward(self , X):\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = int((H - self.pool_h) // self.stride + 1)\n",
    "        out_w = int((W - self.pool_w) // self.stride + 1)\n",
    "        \n",
    "        col = self._im2col(X , self.pool_h , self.pool_w)\n",
    "        col = col.reshape(-1 , self.pool_h * self.pool_w)\n",
    "        \n",
    "        arg_max = np.argmax(col , axis = 1)\n",
    "        A = np.max(col , axis=1)\n",
    "        A = A.reshape(N , out_h , out_w , C).transpose(0 , 3 , 1 , 2)\n",
    "        \n",
    "        self.X = X\n",
    "        self.arg_max = arg_max\n",
    "        \n",
    "        return A\n",
    "        \n",
    "    def backward(self , dA):\n",
    "        dA = dA.transpose(0 , 2 , 3 , 1)\n",
    "\n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dA.size , pool_size))\n",
    "        dmax[np.arange(self.arg_max.size) , self.arg_max.flatten()] = dA.flatten()\n",
    "        dmax = dmax.reshape(dA.shape + (pool_size , ))\n",
    "\n",
    "        dcol = dmax.reshape(dA.shape[0] * dmax.shape[1] * dmax.shape[2] , -1)\n",
    "        dX = self._col2im(dcol , self.X , self.pool_h , self.pool_w )\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \n",
    "    def forward(self , X):\n",
    "        self.X = X\n",
    "        N , C , H , W = self.X.shape\n",
    "        a = self.X.reshape(N , -1)\n",
    "        return a \n",
    "    \n",
    "    def backward(self , da):\n",
    "        x = self.X.shape\n",
    "        da = da.reshape(x)\n",
    "        return da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "             X_train , y_train_one_hot , test_size = 0.20)\n",
    "\n",
    "X_train = X_train.reshape(-1 , 1 , 28 , 28)\n",
    "X_val = X_val.reshape(-1 , 1 , 28 , 28)\n",
    "X_test = X_test.reshape(-1 , 1 , 28 , 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC():\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2 , initializer, optimizer , sigma=0.01):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        # 初期化\n",
    "        self.W = self.initializer.W(self.n_nodes1 , self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        self.hw = 0\n",
    "        self.hb = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"   \n",
    "        self.X = X\n",
    "        self.A = np.dot(self.X , self.W) + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dW = np.dot(self.X.T , dA)\n",
    "        self.dB = np.sum(dA , axis = 0)\n",
    "        dZ = np.dot(dA , self.W.T)\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(dcol , X , filter_h , filter_w , stride=1 , pad=0):\n",
    "    N , C , H , W = X.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = dcol.reshape(N , out_h , out_w , C , filter_h , filter_w).transpose(0,3,4,5,1,2)\n",
    "    \n",
    "    img = np.zeros((N , C , H + 2*pad + stride-1 , W + 2*pad + stride-1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[: , : , y:y_max:stride , x:x_max:stride] += col[: , : , y , x , : , :]\n",
    "            \n",
    "    return img[: , : , pad:H+pad , pad:W+pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    def __init__(self , n_filter , n_channels , filter_h , filter_w):\n",
    "        self.n_filter = n_filter\n",
    "        self.n_channels = n_channels\n",
    "        self.filter_h = filter_h\n",
    "        self.filter_w  = filter_w\n",
    "    \n",
    "    def W(self):\n",
    "        sigma =  np.sqrt(2.0 / self.n_channels)\n",
    "        self.W = sigma * np.random.randn(self.n_filter , self.n_channels , self.filter_h , self.filter_w)\n",
    "        return self.W\n",
    "    \n",
    "    def B(self):\n",
    "        sigma =  np.sqrt(2.0 / self.n_channels)\n",
    "        self.B = sigma * np.random.randn(self.n_filter)\n",
    "        return self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer():\n",
    "\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, filter_num, filter_size):\n",
    "        W = self.sigma * np.random.randn(filter_num , filter_size)\n",
    "        \n",
    "        return W\n",
    "    def B(self, filter_size):\n",
    "        B = self.sigma * np.random.randn(filter_size)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self , x):\n",
    "        self.mask = (x <= 0)\n",
    "        self.A = x.copy()\n",
    "        self.A[self.mask] = 0\n",
    "        return self.A\n",
    "        \n",
    "    def backward(self , dA):\n",
    "        dA[self.mask] = 0\n",
    "        dA = dA\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Conv2d:\n",
    "    def __init__(self , W , B  , stride=1 , pad=0 , optimizer=AdaGrad(lr=0.01)):\n",
    "        self.W = W\n",
    "        self.B = B\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        self.hw = 0\n",
    "        self.hb = 0\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def _out_h(self , H , FH , pad_h=0 , stride_h=1):\n",
    "        self.out_h = int(H + 2*pad_h - FH // stride_h+1)\n",
    "        return self.out_h        \n",
    "\n",
    "    def _out_w(self , W , FW , pad_w=0 , stride_w=1):\n",
    "        self.out_w = int(W + 2*pad_w - FW // stride_w+1)\n",
    "        return self.out_w\n",
    "    \n",
    "    def _im2col(self , X , FH , FW):\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = self._out_h(H , FH)\n",
    "        out_w = self._out_w(W , FW)\n",
    "\n",
    "        img = np.pad(X , [(0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)] , \"constant\")\n",
    "        col = np.zeros((N , C , FH , FW , out_h , out_w))\n",
    "\n",
    "        for y in range(FH):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + self.stride*out_w\n",
    "                col[: , : , y , x , : , :] = img[: , : , y:y_max:self.stride, x:x_max:self.stride]\n",
    "\n",
    "        col = col.transpose(0 , 4 , 5 , 1 , 2 , 3).reshape(N*out_h*out_w, -1)\n",
    "        return col\n",
    "\n",
    "    def _col2im(self , dcol , X , FH , FW):\n",
    "        N , C , H , W = self.X.shape\n",
    "        out_h = self._out_h(H , FH)\n",
    "        out_w = self._out_w(W , FW)\n",
    "        col = dcol.reshape(N , out_h , out_W , C , FH , FW).transpose(0,3,4,5,1,2)\n",
    "\n",
    "        img = np.zeros(N , C , H , 2*self.pad + self.stride-1 , W + 2*self.pad + self.stride-1)\n",
    "        for y in range(FH):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + self.stride*out_w\n",
    "                img[: , : , y:y_max:self.stride , x:x_max:self.stride] += col[: , : , y , x , : , :]\n",
    "\n",
    "        return img[: , : , pad:H+pad , pad:W+pad]\n",
    "    \n",
    "    def forward(self , X):\n",
    "        FN , C , FH , FW = self.W.shape\n",
    "        N , C , H , W = X.shape\n",
    "        out_h = self._out_h(H , FH)\n",
    "        out_w = self._out_w(W , FW)\n",
    "        \n",
    "        col = self._im2col(X , FH , FW)\n",
    "        col_W = self.W.reshape(FN , -1).T\n",
    "        \n",
    "        A = np.dot(col , col_W) + self.B\n",
    "        A = A.reshape(N , out_h , out_w , -1).transpose(0 , 3 , 1 , 2)\n",
    "        self.X = X\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self , dA):\n",
    "        FN , C , FH , FW = self.W.shape\n",
    "        dA = dA.transpose(0 , 2 , 3 , 1).reshape(-1 , FN)\n",
    "        \n",
    "        self.dB = np.sum(dA , axis = 0)\n",
    "        self.dW = np.dot(self.col.T , dA)\n",
    "        self.dW = self.dW.transpose(1 , 0).reshape(FN , C , FH ,FW)\n",
    "        \n",
    "        dcol = np.dot(dA , self.col_W.T)\n",
    "        dX = col2im(dcol , self.X  , FH , FW)\n",
    "        \n",
    "        self = self.optimizer.update(self)\n",
    "        return dX\n",
    "    \n",
    "class SGD():\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return layer.W , layer.B\n",
    "    \n",
    "class AdaGrad():\n",
    "    def __init__(self , lr):\n",
    "        self.lr = lr\n",
    "        self.hw = None\n",
    "        self.hb = None\n",
    "    \n",
    "    def update(self , layer):\n",
    "        \n",
    "        layer.hw += (layer.dW) * (layer.dW)\n",
    "        layer.W -= self.lr * (layer.dW) / (np.sqrt(layer.hw) + 1e-7)\n",
    "        layer.hb += (layer.dB) * (layer.dB)\n",
    "        layer.B -= self.lr * (layer.dB) / (np.sqrt(layer.hb) + 1e-7)\n",
    "        self.hw = layer.hw\n",
    "        self.hb = layer.hb\n",
    "        return layer.W, layer.B  \n",
    "\n",
    "class SoftmaxWithLoss():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        if x.ndim == 2:\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            return y.T\n",
    "        x = x - np.max(x)\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "    \n",
    "    def backward(self , z , y):\n",
    "        self.dA = z - y\n",
    "        return self.dA\n",
    "    \n",
    "    def Loss(self , z , y):\n",
    "        loss =  -np.sum(y * np.log(z) + 1e-7) / y.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "\n",
    "    def __init__(self,F_num = 30 ,C =1, FW = 3 , FH = 3 , pool_w = 2, pool_h = 2 ,pad = 0 ,stride = 1 ,\n",
    "                            epochs = 1,lr = 0.001 ,sigma = 0.01,n_nodes1= 400 , n_nodes2 = 200 , n_output = 10 ,\n",
    "                             batch_size = 20, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        n_features = X_train.shape[1]\n",
    "        self.n_features = n_features\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.loss = []\n",
    "        self.epochs = epochs\n",
    "        self.F_num = F_num\n",
    "        self.C = C\n",
    "        self.FW = FW\n",
    "        self.FH = FH\n",
    "        self.pool_w = pool_w\n",
    "        self.pool_h = pool_h\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        N , C , H , W = X_train.shape\n",
    "        out_h = int(H + 2*self.pad - self.FH // self.stride+1)\n",
    "        out_w = int(H + 2*self.pad - self.FH // self.stride+1)\n",
    "        out_h2 = out_h // self.pool_h\n",
    "        out_w2 = out_w //  self.pool_w\n",
    "        self.num = int(self.F_num * C * out_h2 * out_w2)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "   \n",
    "        Xavi = HeInitializer(self.F_num , self.C , self.FW , self.FH)\n",
    "        self.W = Xavi.W()\n",
    "        self.B = Xavi.B()\n",
    "        optimizer = AdaGrad(self.lr)\n",
    "        self.Con = _Conv2d(self.W,self.B)\n",
    "        self.pool = MaxPool2D(self.pool_h , self.pool_w)\n",
    "        self.activation1 = ReLU()\n",
    "        self.fla   = Flatten()\n",
    "        self.FC =  FC(self.num  , self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation2 = SoftmaxWithLoss()\n",
    "        \n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            self.get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "            for self.mini_X_train, self.mini_y_train in get_mini_batch:\n",
    "                A1 = self.Con.forward(self.mini_X_train)\n",
    "                A2 = self.pool.forward(A1)\n",
    "                Z1 = self.activation1.forward(A2)\n",
    "                F =  self.fla.forward(Z1)\n",
    "                A3 = self.FC.forward(F)\n",
    "                Z3 = self.activation2.forward(A3)\n",
    "                \n",
    "                dA3 = self.activation2.backward(Z3 , self.mini_y_train) \n",
    "                dZ2 = self.FC.backward(dA3)\n",
    "                dF =  self.fla.backward(dZ2)\n",
    "                dA2 = self.activation1.backward(dF)\n",
    "                dA1 = self.pool.backward(dA2)\n",
    "                dZ1 = self.Con.backward(dA1)\n",
    "                self.c_loss = self.activation2.Loss(Z3 , self.mini_y_train)\n",
    "            self.loss = np.append(self.loss , self.c_loss)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print()\n",
    "\n",
    "    def _predict(self, X):\n",
    "        A1 = self.Con.forward(X)\n",
    "        A2 = self.pool.forward(A1)\n",
    "        Z1 = self.activation1.forward(A2)\n",
    "        F =  self.fla.forward(Z1)\n",
    "        A3 = self.FC.forward(F)\n",
    "        Z3 = self.activation2.forward(A3)\n",
    "        self.y_pred = np.argmax(Z3 , axis = 1)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def accuracy(self , X , t):\n",
    "        y_pred = self._predict(X)\n",
    "        return np.sum(y_pred == t) / float(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(epochs = 5, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9711\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:{}\".format(cnn.accuracy(X_test , y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
